
<!DOCTYPE html>
<html>

<head lang="en">
    <meta charset="UTF-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">

    <title>NerVE</title>

    <meta name="description" content="">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel='icon' href='/icons/icon-bulb-2-512.png' sizes='512x512'>

    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/css/bootstrap.min.css">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.css">
    <link rel="stylesheet" href="css/app.css">

    <link rel="stylesheet" href="css/bootstrap.min.css">

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/js/bootstrap.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/1.5.3/clipboard.min.js"></script>


    
    <script src="js/app.js"></script>
</head>

<body>
    <div class="container" id="main">
        <div class="row">
            <h1 class="col-md-12 text-center">
                <b>NerVE: Neural Volumetric Edges for Parametric Curve <br> Extraction from Point Cloud <br>
                <small>
                    CVPR 2023
                </small>
            </h1>
        </div>
        <div class="row">
            <div class="col-md-12 text-center">
                <ul class="list-inline">
                    <li>
                        <!-- <a href="https://lingtengqiu.github.io/"> -->
                            Xiangyu Zhu
                        </a><sup>12*</sup>
                    </li>
                    <li>
                        <a href="https://dongdu3.github.io/">
                            Dong Du
                        </a><sup>1*</sup>
                    </li>
                    <li>
                        <a href="http://chenweikai.github.io/">
                            Weikai Chen
                        </a><sup>3</sup>
                    </li><br>
                    <li>
                            Zhiyou Zhao
                        </a><sup>1</sup>
                    </li>
                    <li>
                        <a href="https://yinyunie.github.io/">
                            Yinyu Nie
                        </a><sup>4</sup>
                    </li>
                    <li>
                        <a href="https://gaplab.cuhk.edu.cn/">
                            Xiaoguang Han
                        </a><sup>12#</sup>
                    </li>
                    <!-- Inc. -->
                    <br>
                    <li>
                        <small>
                            <sup>1</sup>SSE, CUHK-Shenzhen
                        </small>
                    </li>
                    <li>
                        <small>
                            <sup>2</sup>FNii, CUHK-Shenzhen
                        </small>
                    </li>
                    <li>
                        <small>
                            <sup>3</sup>Tencent America
                        </small>
                        
                    </li>
                    <li>
                        <small><sup>4</sup>Technical University of Munich
                        
                    </li>
                </ul>
            </div>
        </div>



        <div class="row">
                <div class="col-md-4 col-md-offset-4 text-center">
                    <ul class="nav nav-pills nav-justified">
                        <li>
                            <a href="https://arxiv.org/pdf/2303.16465.pdf">
                            <image src="./icons/paper.png" height="60px">
                                <h4><strong>Paper</strong></h4>
                            </a>
                        </li>
                        <li>
                            <a href="https://www.youtube.com/watch?v=tAwC23uybTM">
                            <image src="./icons/youtube.png" height="60px">
                                <h4><strong>Video</strong></h4>
                            </a>
                        </li>
                        <li>
                            <a href="https://github.com/uhzoaix/NerVE">
                            <image src="./icons/github.png" height="60px">
                                <h4><strong>Code</strong></h4>
                            </a>
                        </li>
                    </ul>
                </div>
        </div>



        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Abstract
                </h3>
                <image src="./images/teaser.png" class="img-responsive" alt="overview"><br>
                    <p class="text-center">
                        <strong>
                            Figure 1. Our NerVE compared with previous methods for parametric curve extraction from point clouds.
                        </strong>
                    </p>
                <p class="text-justify">
                    Extracting parametric edge curves from point clouds is a fundamental problem in 3D vision and geometry processing. 
                    Existing approaches mainly rely on keypoint detection, a challenging procedure that tends to generate noisy output, making the subsequent edge extraction error-prone.
                    To address this issue, we propose to directly detect structured edges to circumvent the limitations of the previous point-wise methods.
                    We achieve this goal by presenting NerVE, a novel neural volumetric edge representation that can be easily learned through a volumetric learning framework.
                    NerVE can be seamlessly converted to a versatile piece-wise linear (PWL) curve representation, enabling a unified strategy for learning all types of free-form curves. 
                    Furthermore, as NerVE encodes rich structural information, we show that edge extraction based on NerVE can be reduced to a simple graph search problem.
                    After converting NerVE to the PWL representation, parametric curves can be obtained via off-the-shelf spline fitting algorithms.We evaluate our method on the challenging 
                    <a href="https://cs.nyu.edu/~zhongshi/publication/abc-dataset/">ABC dataset</a>. We show that a simple network based on NerVE can already outperform the previous state-of-the-art methods by a great margin.                           
                </p><br>
            </div>
        </div>



        <!-- <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Video
                </h3>
                <div class="text-center">
                    <div style="position:relative;padding-top:56.25%;">
                        <iframe src="./media/demo.mp4" allowfullscreen style="position:absolute;top:0;left:0;width:100%;height:100%;"></iframe>
                    </div>
                </div>
        </div> -->



        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Methodology
                </h3>
                    <image src="./images/cube_definition.png" class="img-responsive" alt="cube representation"><br>
                    <!-- <image src="./images/cube_definition.png" style="max-width:70%;max-height:70%;vertical-align: middle; justify-content: center; align-items: center; margin: 0 auto;" alt="cube representation"><br> -->
                    
                    <p class="text-center">
                        <strong>
                            Figure 2. Definition of the tree attributes in NerVE (a) and the illustration of PWL curve extration from NerVE (b).
                        </strong>
                    </p>
                <p class="text-justify">
                    We present a new paradigm to generate accurate parametric curves using our neural volumetric edge representation, named NerVE. 
                    Firstly, we introduce the definition of NerVE and then propose a dedicated network to learn NerVE that supports direct estimation of structured 3D edges. As shown in Figure 2, 
                    (a) each cube in NerVE contains three attributes: 
                    1) edge occupancy o. o &isin; {0, 1}, which is a binary value to define whether the cube contains edges; 
                    2) edge orientations e. e<sub>i</sub> &isin; {0, 1}, i=1,2,3, which are 3 binary values that represent whether the cube should connect with the adjacent cubes to construct pieces of edges. 
                    Note that a cube has 6 faces and shares with its neighbors, thus we define only three statuses on the left, bottom, and back faces in a cube; 
                    3) edge point position p, which defines an edge point in the cube. With the three defined attributes, we can discretize continuous curves in a unified and regular volumetric representation, 
                    which can be learned directly via neural networks. (b) We can easily extract edges from the defined or learned NerVE cubes.
                    These edges compose PWL curves that can not only provide precise edge positions but also contain valuable topology information, which eases the difficulty of extracting parametric curves. 
                </p><br>
                
                <image src="./images/pipeline.png" class="img-responsive" alt="method"><br>
                    <p class="text-center">
                        <strong>
                            Figure 3. Overview of our proposed network for learning NerVE.
                        </strong>
                    </p>
                <p class="text-justify">
                    Given a point cloud, we first utilize a simplified <a href="https://proceedings.neurips.cc/paper/2017/file/d8bf84be3800d12f74d8b05e9b89836f-Paper.pdf">PointNet++</a> module and a 3D CNN module to obtain the feature grid (has 
                    the same resolution of our NerVE. Three individual decoders are applied to process cube features in the grid to predict the corresponding three attributes of NerVE, i.e., edge occupancy, edge orientation, 
                    and edge point position. With the PWL curves extracted from the NerVE cubes, we further utilize a simple post-processing procedure to correct for their topology errors. 
                    Finally, parametric curves can be obtained using a straightforward graph search and spline fitting algorithm. The pipeline of our method is illustrated in Figure 3.
                </p><br>
            </div>
        </div>



        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Qualitative Results
                </h3>
                <image src="./images/compare_DEF_quali.png" class="img-responsive" alt="qualitative"><br>
                <p class="text-center">
                    <strong>
                        Figure 4. Qualitative comparisons with <a href="https://dl.acm.org/doi/abs/10.1145/3528223.3530140">DEF</a> on parametric curve extraction.
                    </strong>
                </p>
                <image src="./images/compare_edge_quali.jpg" class="img-responsive" alt="qualitative"><br>
                <p class="text-center">
                    <strong>
                        Figure 5. Qualitative comparisons with <a href="https://ieeexplore.ieee.org/document/5669298">VCM</a>, <a href="https://openaccess.thecvf.com/content_ECCV_2018/papers/Lequan_Yu_EC-Net_an_Edge-aware_ECCV_2018_paper.pdf">EC-NET</a> 
                        and <a href="https://proceedings.neurips.cc/paper/2020/file/e94550c93cd70fe748e6982b3439ad3b-Paper.pdf">PIE-NET</a> on edge points estimation.
                    </strong>
                </p><br>

                <image src="./images/more_results_quali.jpg" class="img-responsive" alt="qualitative"><br>
                <p class="text-center">
                    <strong>
                        Figure 6. More qualitative results of our method.
                    </strong>
                </p>

            </div>
        </div>

            
        <!-- <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    BibTeX
                </h3>
                <div class="form-group col-md-10 col-md-offset-1">
                    <textarea id="bibtex" class="form-control" readonly>
                        @inproceedings{zhu2023nerve,
                        title={NerVE: Neural Volumetric Edges for Parametric Curve Extraction from Point Cloud},
                        author={Zhu, Xiangyu and Du, Dong and Chen, Weikai and Zhao, Zhiyou and Nie, Yinyu and Han, Xiaoguang},
                        booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
                        pages={??--??},
                        year={2023}
                        }
                    </textarea>
                </div>
            </div>
        </div> -->

        <section class="section" id="BibTeX">
            <div class="container is-max-desktop content">
              <h2 class="title">BibTeX</h2>
              <pre><code>
                @inproceedings{zhu2023nerve,
                    title={NerVE: Neural Volumetric Edges for Parametric Curve Extraction from Point Cloud},
                    author={Zhu, Xiangyu and Du, Dong and Chen, Weikai and Zhao, Zhiyou and Nie, Yinyu and Han, Xiaoguang},
                    booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
                    pages={13601--13610},
                    year={2023}
                  }                  
              </code></pre>
            </div>
        </section>

        <div class="row">
            <div class="container is-max-desktop content">
                <h3>
                    Acknowledgements
                </h3>
                <p class="text-justify">
                    <!-- This work was partially supported by the National Key R&D Program of China (No.2018YFB1800800), the Basic Research Project No.~HZQB-KCZYZ-2021067 of Hetao Shenzhen-HK S&T Cooperation Zone, and Hong Kong RGC GRF grant (project# 17203119).
                    <br> -->
                    The website template was borrowed from <a href="http://mgharbi.com/">MichaÃ«l Gharbi</a>.
                </p>
            </div>
        </div>
    </div>
</body>
</html>